{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c052ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- CONFIG ---\n",
    "input_csv = \"22118_mag.csv\"  # <-- Set your file path\n",
    "output_csv = \"binned_summary2.csv\"\n",
    "lat_col = \"lat\"\n",
    "lon_col = \"lon\"\n",
    "\n",
    "lithium_valley_coords =  [\n",
    "  (-115.8, 33.0),\n",
    "  (-115.4, 33.0),\n",
    "  (-115.4, 33.4),\n",
    "  (-115.8, 33.4),\n",
    "  (-115.8, 33.0)\n",
    "]\n",
    "\n",
    "# --- LOAD DATA ---\n",
    "df = pd.read_csv(input_csv)\n",
    "df.columns = df.columns.str.strip()  # Remove accidental whitespace in headers\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a38e72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ratth\\AppData\\Local\\Temp\\ipykernel_5536\\3845983222.py:7: DeprecationWarning: The 'shapely.vectorized.contains' function is deprecated and will be removed a future version. Use 'shapely.contains_xy' instead (available since shapely 2.0.0).\n",
      "  mask = vectorized.contains(lithium_valley_polygon, df[lon_col].values, df[lat_col].values)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data shape: (15862036, 27) ORIGINAL (15862036, 27)\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import Polygon\n",
    "from shapely import vectorized\n",
    "\n",
    "lithium_valley_polygon = Polygon(lithium_valley_coords)\n",
    "\n",
    "# REMOVED THE LV FILTERING \n",
    "mask = vectorized.contains(lithium_valley_polygon, df[lon_col].values, df[lat_col].values)\n",
    "df_filtered = df#[mask].copy()\n",
    "print(f\"Filtered data shape: {df_filtered.shape}\", 'ORIGINAL', df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb96bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- BINNING ---\n",
    "bin_size = 0.002  # Bin size found by a grid search to minimize the nulls while maximizing the granularity with the rounding integer as well. \n",
    "df_filtered['lat_bin'] = (df_filtered[lat_col] / bin_size).round(0) * bin_size\n",
    "df_filtered['lon_bin'] = (df_filtered[lon_col] / bin_size).round(0) * bin_size\n",
    "\n",
    "# --- AGGREGATION ---\n",
    "group_cols = ['lat_bin', 'lon_bin']\n",
    "numeric_cols = df_filtered.select_dtypes(include=[np.number]).columns.tolist()\n",
    "agg_funcs = ['mean']# 'max', 'count'] # Mean is the standard practice, verified that the median and mean were about the same \n",
    "agg_dict = {col: agg_funcs for col in numeric_cols if col not in group_cols}\n",
    "summary = df_filtered.groupby(group_cols).agg(agg_dict).reset_index()\n",
    "\n",
    "\n",
    "\n",
    "summary.columns = [f\"{col}_{stat}\" if stat else f\"{col}\" for col, stat in summary.columns]\n",
    "#summary.to_csv(output_csv, index=False)\n",
    "#print(f\"Binned and aggregated summary written to: {output_csv}\")\n",
    "\n",
    "\n",
    "value_cols = summary.columns #['comp_mag_mean',]  # Make sure this exists after aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77c7aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('binned_geoflight.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4177928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 39188 rows x 34 columns to Geoflight_z2+_percentile.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import pandas as pd\n",
    "\n",
    "### OLD EDA \n",
    "threshold =2 \n",
    "not_plot = ['lon','lat','x','y','base','fid']\n",
    "show = [\n",
    "    'calc_radar_mean',\n",
    "    'comp_mag_mean',\n",
    "    'dc_lvl_mag_mean',\n",
    "    'dem_mean',\n",
    "    'diurnal_corrected_mag_mean',\n",
    "    'drape_mean',\n",
    "    'filtered_base_mean',\n",
    "    'final_mag_mean',\n",
    "    'igrf_base_cor_mean',\n",
    "    'igrf_cor_mean',\n",
    "    'micro_level_adjustment_mean',\n",
    "    'micro_level_mag_mean',\n",
    "    'micro_level_surface_mean',\n",
    "    'radar_mean',\n",
    "    'raw_mag_mean',\n",
    "    'gps_elev_mean'\n",
    "]\n",
    "\n",
    "layers = [col for col in value_cols if col in show]\n",
    "residuals_dict = {}\n",
    "\n",
    "for value_col in layers:\n",
    "    if value_col in summary.columns and \"lat\" not in value_col and \"lon\" not in value_col:\n",
    "        # Pivot to grid\n",
    "        pivot = summary.pivot_table(index='lat_bin', columns='lon_bin', values=value_col)\n",
    "\n",
    "        # Residuals (Anomaly Enhancement)\n",
    "        regional = pivot.rolling(window=15, min_periods=1, center=True).mean()\n",
    "        residuals = pivot - regional\n",
    "\n",
    "        # Normalize\n",
    "        std = np.nanstd(residuals.values)\n",
    "        norm_residuals = residuals / std if std != 0 else residuals\n",
    "\n",
    "        # Flatten to long\n",
    "        flat = norm_residuals.reset_index().melt(\n",
    "            id_vars='lat_bin',\n",
    "            var_name='lon_bin',\n",
    "            value_name=f\"{value_col}_stdnorm\"\n",
    "        )\n",
    "\n",
    "        # Add percentile column\n",
    "        flat[f\"{value_col}_percentile\"] = norm.cdf(flat[f\"{value_col}_stdnorm\"]) * 100\n",
    "\n",
    "        # Filter: Only keep abs(stdnorm) > threshold and finite/notnull\n",
    "        flat = flat[\n",
    "            flat[f\"{value_col}_stdnorm\"].notnull() &\n",
    "            np.isfinite(flat[f\"{value_col}_stdnorm\"]) &\n",
    "            (flat[f\"{value_col}_stdnorm\"].abs() > threshold)\n",
    "        ]\n",
    "\n",
    "        # Merge into dict by key (lat_bin, lon_bin)\n",
    "        for _, row in flat.iterrows():\n",
    "            key = (row['lat_bin'], row['lon_bin'])\n",
    "            if key not in residuals_dict:\n",
    "                residuals_dict[key] = {'lat_bin': row['lat_bin'], 'lon_bin': row['lon_bin']}\n",
    "            residuals_dict[key][f\"{value_col}_stdnorm\"] = row[f\"{value_col}_stdnorm\"]\n",
    "            residuals_dict[key][f\"{value_col}_percentile\"] = row[f\"{value_col}_percentile\"]\n",
    "\n",
    "# Create final DataFrame\n",
    "df_final = pd.DataFrame(list(residuals_dict.values()))\n",
    "df_final.sort_values(['lat_bin', 'lon_bin'], inplace=True)\n",
    "df_final.to_csv('Geoflight_z2+_percentile.csv', index=False)\n",
    "print(f\"Saved {df_final.shape[0]} rows x {df_final.shape[1]} columns to Geoflight_z2+_percentile.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd8f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for value_col in summary.columns:\n",
    "    # Pivot to grid\n",
    "    pivot = summary.pivot_table(index='lat_bin', columns='lon_bin', values=value_col)\n",
    "    lats = pivot.index.values\n",
    "    lons = pivot.columns.values\n",
    "\n",
    "    # 1. Raw Mean Heatmap\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(f'Raw Mean Heatmap: {value_col}')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.imshow(\n",
    "        pivot,\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        extent=[lons.min(), lons.max(), lats.min(), lats.max()],\n",
    "        cmap='RdBu'\n",
    "    )\n",
    "    plt.colorbar(label=value_col)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Residuals (Anomaly Enhancement)\n",
    "    regional = pivot.rolling(window=15, min_periods=1, center=True).mean()\n",
    "    residuals = pivot - regional\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(f'Residuals (Local Anomaly): {value_col}')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.imshow(\n",
    "        residuals,\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        extent=[lons.min(), lons.max(), lats.min(), lats.max()],\n",
    "        cmap='seismic'\n",
    "    )\n",
    "    plt.colorbar(label=f'{value_col} Residual')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Z-Score Map (Standardized Anomalies)\n",
    "    pivot_flat = pivot.stack()\n",
    "    zscore = (pivot - pivot_flat.mean()) / pivot_flat.std()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.title(f'Z-Score Map: {value_col}')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.imshow(\n",
    "        zscore,\n",
    "        aspect='auto',\n",
    "        origin='lower',\n",
    "        extent=[lons.min(), lons.max(), lats.min(), lats.max()],\n",
    "        cmap='seismic'\n",
    "    )\n",
    "    plt.colorbar(label='Z-score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
